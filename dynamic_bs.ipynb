{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import heapq\n",
    "import queue\n",
    "from tqdm import tqdm\n",
    "from typing import Callable,List,Tuple,Dict\n",
    "\n",
    "cmap = plt.get_cmap('tab20') # type: ignore\n",
    "State=Dict[any,int] # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(G:nx.Graph,state:State=None,label=False):\n",
    "    if state is None:\n",
    "        nx.draw(G, node_size = 80, alpha = 0.8)\n",
    "        plt.show()\n",
    "    else:\n",
    "        map= [v for _,v in state.items()]\n",
    "        u=np.unique(map)\n",
    "        fixed_map=[np.where(u==i)[0][0] for i in map]\n",
    "        node_cmap = [cmap(v) for v in fixed_map]\n",
    "        \n",
    "        pos = nx.spring_layout(G,seed=40)\n",
    "        # add label too nodes\n",
    "        if label:\n",
    "            labels = {node:node for node in G.nodes()}\n",
    "            nx.draw_networkx_labels(G, pos, labels, font_size=9)\n",
    "            \n",
    "        nx.draw(G, pos, node_size = 80, alpha = 0.8, node_color=node_cmap)\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_partitions(state:State)->List[State]:\n",
    "    comm_dict = {}\n",
    "    for node,comm in state.items():\n",
    "        if comm in comm_dict:\n",
    "            comm_dict[comm].add(node)\n",
    "        else:\n",
    "            comm_dict[comm] = {node}\n",
    "    return list(comm_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitions_state(partitions):\n",
    "    state = {}\n",
    "    for i,comm in enumerate(partitions):\n",
    "        for node in comm:\n",
    "            state[node] = i\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_alea(G:nx.Graph,nb_communities=None)->State:\n",
    "    if nb_communities is None: nb_communities = len(G.nodes())\n",
    "    if (nb_communities>len(G.nodes())): raise ValueError(\"nb_communities must be less than the number of nodes\")\n",
    "\n",
    "    state = {node:np.random.randint(0,nb_communities) for node in G.nodes()}\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_greedy(G:nx.Graph)->State:\n",
    "    partitions= nx.algorithms.community.greedy_modularity_communities(G)\n",
    "    state=partitions_state(partitions)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(G, state):\n",
    "    if (len(G.nodes)<=1 or G.number_of_edges()==0): \n",
    "        return 0\n",
    "    partitions = state_partitions(state)\n",
    "    return nx.algorithms.community.modularity(G, partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(G,state):\n",
    "    \"\"\"\n",
    "    how many nodes in a graph are assigned to a community.\n",
    "    \"\"\"\n",
    "    partitions = state_partitions(state)\n",
    "    return nx.algorithms.community.quality.partition_quality(G,partitions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(G,state):\n",
    "    \"\"\"\n",
    "    measure of how well a community detection algorithm partitions the nodes in \n",
    "    a graph into communities that reflect the underlying structure of the graph.\n",
    "    \"\"\"\n",
    "    partitions = state_partitions(state)\n",
    "    return 1- nx.algorithms.community.quality.partition_quality(G,partitions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpm_modularity(G,state, gamma=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the modularity score of a graph using the Constant Potts Model (CPM).\n",
    "\n",
    "    Parameters:\n",
    "    - Q (nx.Graph): the graph to calculate the modularity score for.\n",
    "    - gamma (float): the resolution parameter of the CPM.\n",
    "\n",
    "    Returns:\n",
    "    - modularity (float): the modularity score of the graph.\n",
    "    \"\"\"\n",
    "    # Get the adjacency matrix of the graph\n",
    "    A = nx.to_numpy_array(G)\n",
    "    n = len(A)\n",
    "\n",
    "    # Get the total weight of the graph\n",
    "    m = np.sum(A) / 2\n",
    "\n",
    "    # Calculate the degree of each node\n",
    "    ki = np.sum(A, axis=1)\n",
    "\n",
    "    # Calculate the modularity matrix\n",
    "    B = A - gamma * np.outer(ki, ki) / (2 * m)\n",
    "\n",
    "    # Calculate the modularity score\n",
    "    \n",
    "    partitions = state_partitions(state)\n",
    "    ci = np.array(list(partitions))\n",
    "    modularity = 0\n",
    "    for c in ci:\n",
    "        c=np.array(list(c))\n",
    "        modularity += np.sum(B[np.ix_(c, c)])\n",
    "    modularity /= (2 * m)\n",
    "\n",
    "    return modularity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration du voisinage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_replacement(G:nx.Graph,state:State,eval)->State:\n",
    "    if(len(set(state.values()))==1):\n",
    "        return state\n",
    "    to_replace = np.random.choice(list(state.keys()))\n",
    "    neighbors = list(G.neighbors(to_replace))\n",
    "    # get neighbors that are not in the same community\n",
    "    neighbors = [n for n in neighbors if state[n] != state[to_replace]]\n",
    "    if len(neighbors)==0:\n",
    "        return state\n",
    "        \n",
    "    replacement = np.random.choice(neighbors)\n",
    "    new_state = state.copy()\n",
    "    new_state[to_replace] = state[replacement]\n",
    "    if eval(G,new_state) > eval(G,state):\n",
    "        return new_state\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deplacement(G,state:State,eval):\n",
    "    if(len(set(state.values()))==1):\n",
    "        return state\n",
    "    # choose random community\n",
    "    community = np.random.choice(list(set(state.values())))\n",
    "    # choose random nodes in community\n",
    "    community_nodes = [node for node in state.keys() if state[node] == community]\n",
    "    number_of_nodes_to_move = np.random.randint(1,len(community_nodes)+1)\n",
    "    nodes_to_move = np.random.choice(community_nodes, number_of_nodes_to_move, replace=False)\n",
    "    # choose random community to move to\n",
    "    new_community = np.random.choice(list(set(state.values()) - set([community])))\n",
    "    new_state = state.copy()\n",
    "    for node in nodes_to_move:\n",
    "        new_state[node] = new_community\n",
    "    if eval(G,new_state) > eval(G,state):\n",
    "        return new_state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_fusion(G,state:State,eval):\n",
    "    if(len(set(state.values()))==1):\n",
    "        return state\n",
    "    # choose random community\n",
    "    community = np.random.choice(list(set(state.values())))\n",
    "    # choose random community to fuse with\n",
    "    new_community = np.random.choice(list(set(state.values()) - set([community])))\n",
    "    new_state = state.copy()\n",
    "    for node in new_state.keys():\n",
    "        if new_state[node] == community:\n",
    "            new_state[node] = new_community\n",
    "    if eval(G,new_state) > eval(G,state):\n",
    "        return new_state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustif_cross_mutation(G,history:List[Tuple[float,State]],N:int,eval)->List[Tuple[float,State]]:\n",
    "    if len(history) < 2:\n",
    "        return history\n",
    "    # choose random node\n",
    "    node = np.random.choice(list(history[-1][1].keys()))\n",
    "    # get nodes of the same community in every state\n",
    "    neighbor_communities = []\n",
    "    for _,state in history:\n",
    "        comm=state[node]\n",
    "        nodes_to_cross = [node for node in state.keys() if state[node] == comm]\n",
    "        neighbor_communities.append(nodes_to_cross)\n",
    "\n",
    "    states_cross=history.copy()\n",
    "    for i,(_,state) in enumerate(history):\n",
    "        for j,neighbor_community in enumerate(neighbor_communities):\n",
    "            if(i==j):\n",
    "                continue\n",
    "\n",
    "            new_state = state.copy()\n",
    "            for neighbor in neighbor_community:\n",
    "                new_state[neighbor] = history[j][1][node]\n",
    "            # check if new state already exists in history\n",
    "            if(new_state in [state for _,state in states_cross]):\n",
    "                continue\n",
    "            mod=eval(G,new_state)\n",
    "            candidate = (mod, new_state)\n",
    "            states_cross.append(candidate)\n",
    "    \n",
    "    states_cross=heapq.nlargest(N, states_cross,key=lambda x: x[0])\n",
    "\n",
    "    return states_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_mutation(G:nx.Graph,history:List[Tuple[float,State]],N:int,eval)->List[Tuple[float,State]]:\n",
    "    if len(history) < 2:\n",
    "        return history\n",
    "    # choose random node\n",
    "    states_cross=history.copy()\n",
    "\n",
    "    node = np.random.choice(list(history[-1][1].keys()))\n",
    "    # get two random states in history\n",
    "    i,j = np.random.choice(range(len(history)), 2, replace=False)\n",
    "    if i == j:\n",
    "        return history\n",
    "        \n",
    "    state1=history[i][1]\n",
    "    state2=history[j][1]\n",
    "    neighbors_1 = [n for n in state1 if state1[n] == state1[node]]\n",
    "    neighbors_2 = [n for n in state2 if state2[n] == state2[node]]\n",
    "\n",
    "    new_C2=state2.copy()\n",
    "    for n in neighbors_1:\n",
    "        new_C2[n]=state1[node]\n",
    "\n",
    "    if (not new_C2 in [state for _,state in states_cross]):\n",
    "        mod=eval(G,new_C2)\n",
    "        candidate = (mod, new_C2)\n",
    "        states_cross.append(candidate)\n",
    "        states_cross=heapq.nlargest(N, states_cross,key=lambda x: x[0])\n",
    "\n",
    "    new_C1=state1.copy()\n",
    "    for n in neighbors_2:\n",
    "        new_C1[n]=state2[node]\n",
    "\n",
    "    if (not new_C1 in [state for _,state in states_cross]):\n",
    "        mod=eval(G,new_C1)\n",
    "        candidate = (mod, new_C1)\n",
    "        states_cross.append(candidate)\n",
    "        states_cross=heapq.nlargest(N, states_cross,key=lambda x: x[0])\n",
    "\n",
    "    return states_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voisinage1=[vertex_replacement,deplacement,community_fusion]\n",
    "def get_successors1(G:nx.Graph,state:State,N:int,eval)->List[Tuple[float,State]]:\n",
    "    successors:List[Tuple[float,State]] = []\n",
    "    for _ in range(N):\n",
    "        new_state=voisinage1[np.random.randint(0,3)](G,state,eval)\n",
    "        mod=eval(G,new_state)\n",
    "        successor=(mod,new_state)\n",
    "        successors.append(successor)\n",
    "        \n",
    "    successors=heapq.nlargest(N, successors,key=lambda x: x[0])\n",
    "    successors=cross_mutation(G,successors,N,eval)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voisinage2=[vertex_replacement,deplacement]\n",
    "def get_successors2(G:nx.Graph,state:State,N:int,eval)->List[Tuple[float,State]]:\n",
    "    successors:List[Tuple[float,State]] = []\n",
    "    for _ in range(N):\n",
    "        new_state=voisinage2[np.random.randint(0,2)](G,state,eval)\n",
    "        new_state=community_fusion(G,new_state,eval)\n",
    "        mod=eval(G,new_state)\n",
    "        successor=(mod,new_state)\n",
    "        successors.append(successor)\n",
    "        \n",
    "    successors=heapq.nlargest(N, successors,key=lambda x: x[0])\n",
    "    successors=cross_mutation(G,successors,N)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors3(G:nx.Graph,state:State,N:int,eval)->List[Tuple[float,State]]:\n",
    "    successors:List[Tuple[float,State]] = []\n",
    "    for _ in range(N):\n",
    "        new_state=vertex_replacement(G,state,eval)\n",
    "        new_state=community_fusion(G,new_state,eval)\n",
    "        mod=eval(G,new_state)\n",
    "        successor=(mod,new_state)\n",
    "        successors.append(successor)\n",
    "        \n",
    "    successors=heapq.nlargest(N, successors,key=lambda x: x[0])\n",
    "    successors=cross_mutation(G,successors,N,eval)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors4(G:nx.Graph,state:State,N:int,eval)->List[Tuple[float,State]]:\n",
    "    successors:List[Tuple[float,State]] = []\n",
    "    for _ in range(N):\n",
    "        new_state=deplacement(G,state,eval)\n",
    "        new_state=community_fusion(G,new_state,eval)\n",
    "        mod=eval(G,new_state)\n",
    "        successor=(mod,new_state)\n",
    "        successors.append(successor)\n",
    "        \n",
    "    successors=heapq.nlargest(N, successors,key=lambda x: x[0])\n",
    "    successors=cross_mutation(G,successors,N),eval\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_successors5(G:nx.Graph,state:State,N:int,eval)->List[Tuple[float,State]]:\n",
    "    successors:List[Tuple[float,State]] = []\n",
    "    sqrt=int(math.sqrt(N))\n",
    "    for _ in range(sqrt+1):\n",
    "        new_state=voisinage2[np.random.randint(0,2)](G,state,eval)\n",
    "        new_state=community_fusion(G,new_state,eval)\n",
    "        mod=eval(G,new_state)\n",
    "        successor=(mod,new_state)\n",
    "        successors.append(successor)\n",
    "        \n",
    "    successors=heapq.nlargest(N, successors,key=lambda x: x[0])\n",
    "    successors=exhaustif_cross_mutation(G,successors,N,eval)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var(beam):\n",
    "    mod = [ sol[0] for sol in beam]\n",
    "    mean = sum(mod)/len(beam)\n",
    "    variance = sum((x - mean) ** 2 for x in mod) / len(mod)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi\n",
    "\n",
    "def similarity(beam):\n",
    "    nmi_values = []\n",
    "    n_partitions = len(beam)\n",
    "    states = [ sol[1] for sol in beam]\n",
    "    partitions = [list(state.values()) for state in states]\n",
    "\n",
    "    for i in range(n_partitions):\n",
    "        for j in range(i + 1, n_partitions):\n",
    "            nmi_values.append(nmi(partitions[i], partitions[j]))\n",
    "\n",
    "    return sum(nmi_values) / len(nmi_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(data):\n",
    "    G = nx.Graph()\n",
    "    if data.x is not None:\n",
    "        G.add_nodes_from(range(data.x.shape[0]))\n",
    "    elif data.num_nodes is not None:\n",
    "        G.add_nodes_from(range(data.num_nodes))\n",
    "\n",
    "    G.add_edges_from(data.edge_index.t().tolist())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "model = pickle.load(open('linearRegression_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam(X):\n",
    "    X = scaler.transform([X])\n",
    "    [result] = model.predict(X)\n",
    "    # round to integer\n",
    "    result = int(round(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearch:\n",
    "    \n",
    "    G:nx.Graph\n",
    "    beam:List[Tuple[float,State]]\n",
    "    best_state:State\n",
    "    get_successors:Callable[[nx.Graph,State,int],List[Tuple[float,State]]]\n",
    "    evaluate:Callable[[nx.Graph,State],float]\n",
    "    beam_width:int\n",
    "    nb_successors:int\n",
    "    history:queue.Queue\n",
    "    \n",
    "\n",
    "    def __init__(self, G:nx.Graph,start_state:State, get_successors:Callable[[nx.Graph,State,int],List[Tuple[float,State]]], evaluate:Callable[[nx.Graph,State],float], beam_width:int=10,nb_successors:int=10,hist_size=False):\n",
    "        \"\"\"\n",
    "        Effectue une recherche par faisceau (beam search).\n",
    "\n",
    "        Args:\n",
    "            start_state (object): L'état initial de la recherche.\n",
    "            beam_width (int): La taille du faisceau (nombre de candidats à considérer).\n",
    "            max_steps (int): Le nombre maximum d'étapes à effectuer.\n",
    "            get_successors (function): la fonction de voisinage qui retourne les successeurs d'un états (voisins).\n",
    "            evaluate (function): Une fonction qui prend un état en argument et retourne une valeur d'évaluation.\n",
    "        Returns:\n",
    "            object: Le meilleur état trouvé par la beam search.\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.beam_width = beam_width\n",
    "        self.get_successors = get_successors\n",
    "        self.evaluate = evaluate\n",
    "        self.modularity=evaluate(G,start_state)\n",
    "        self.beam = [(self.modularity, start_state)]\n",
    "        self.best_state = start_state\n",
    "        self.nb_successors=nb_successors\n",
    "        self.hist_size=hist_size\n",
    "        if hist_size:\n",
    "            self.history=queue.Queue()\n",
    "            self.history.put(self.modularity)\n",
    "\n",
    "    def search(self,max_steps:int):\n",
    "        for _ in tqdm(range(max_steps)):\n",
    "            candidates:List[Tuple[float,State]] = []  # Liste pour stocker les nouveaux candidats pour chaque étape\n",
    "            candidates.extend(self.beam)\n",
    "            for _, state in self.beam:\n",
    "                successors = self.get_successors(self.G,state,self.nb_successors,self.evaluate)\n",
    "                # push successors in candidates\n",
    "                candidates.extend(successors)\n",
    "            self.beam = heapq.nlargest(self.beam_width, candidates,key=lambda x: x[0])  # Sélectionne les meilleurs candidats, la beam c'est l'ensemble des noeuds accepté dans un niveau.\n",
    "            if self.hist_size:\n",
    "                self.history.put(self.beam[0][0])\n",
    "                if(self.history.qsize()>self.hist_size):\n",
    "                    self.history.get()\n",
    "                # if all history are the same\n",
    "                if(self.history.qsize()>=self.hist_size and len(set(list(self.history.queue)))==1):\n",
    "                    break\n",
    "\n",
    "            if self.modularity < self.beam[0][0]:\n",
    "                self.best_state = self.beam[0][1]  # Meilleur état trouvé\n",
    "                self.modularity = self.beam[0][0]\n",
    "        \n",
    "        return self.best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearch_Dynamic:\n",
    "    \n",
    "    G:nx.Graph\n",
    "    beam:List[Tuple[float,State]]\n",
    "    best_state:State\n",
    "    get_successors:Callable[[nx.Graph,State,int],List[Tuple[float,State]]]\n",
    "    evaluate:Callable[[nx.Graph,State],float]\n",
    "    beam_width:int\n",
    "    nb_successors:int\n",
    "    history:queue.Queue\n",
    "    \n",
    "\n",
    "    def __init__(self, G:nx.Graph,start_state:State, get_successors:Callable[[nx.Graph,State,int],List[Tuple[float,State]]], evaluate:Callable[[nx.Graph,State],float], init_beam_width:int=10,nb_successors:int=10,hist_size=False):\n",
    "        \"\"\"\n",
    "        Effectue une recherche par faisceau (beam search).\n",
    "\n",
    "        Args:\n",
    "            start_state (object): L'état initial de la recherche.\n",
    "            beam_width (int): La taille du faisceau (nombre de candidats à considérer).\n",
    "            max_steps (int): Le nombre maximum d'étapes à effectuer.\n",
    "            get_successors (function): la fonction de voisinage qui retourne les successeurs d'un états (voisins).\n",
    "            evaluate (function): Une fonction qui prend un état en argument et retourne une valeur d'évaluation.\n",
    "\n",
    "        Returns:\n",
    "            object: Le meilleur état trouvé par la beam search.\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.beam_width = init_beam_width\n",
    "        self.get_successors = get_successors\n",
    "        self.evaluate = evaluate\n",
    "        self.modularity=evaluate(G,start_state)\n",
    "        self.beam = [(self.modularity, start_state)]\n",
    "        self.best_state = start_state\n",
    "        self.nb_successors=nb_successors\n",
    "        self.hist_size=hist_size\n",
    "        if hist_size:\n",
    "            self.history=queue.Queue()\n",
    "            self.history.put(self.modularity)\n",
    "\n",
    "    def search(self,max_steps:int):\n",
    "        for _ in tqdm(range(max_steps)):\n",
    "            candidates:List[Tuple[float,State]] = []  # Liste pour stocker les nouveaux candidats pour chaque étape\n",
    "            candidates.extend(self.beam)\n",
    "            for _, state in self.beam:\n",
    "                successors = self.get_successors(self.G,state,self.nb_successors,self.evaluate)\n",
    "                # push successors in candidates\n",
    "                candidates.extend(successors)\n",
    "            self.beam = heapq.nlargest(self.beam_width, candidates,key=lambda x: x[0])  # Sélectionne les meilleurs candidats, la beam c'est l'ensemble des noeuds accepté dans un niveau.\n",
    "            if self.hist_size:\n",
    "                self.history.put(self.beam[0][0])\n",
    "                if(self.history.qsize()>self.hist_size):\n",
    "                    self.history.get()\n",
    "                # if all history are the same\n",
    "                if(self.history.qsize()>=self.hist_size and len(set(list(self.history.queue)))==1):\n",
    "                    break\n",
    "            \n",
    "            variance=var(self.beam)\n",
    "            sim=similarity(self.beam)\n",
    "            delta_mod=self.beam[0][0]-self.modularity\n",
    "            nodes_num=self.G.number_of_nodes()\n",
    "            nb_communities=len(set(list(self.best_state.values())))\n",
    "            data=[variance,sim,delta_mod,nodes_num,nb_communities,self.beam[0][0]]\n",
    "            self.beam_width=predict_beam(data)\n",
    "            # TODO: fill beam with cross mutation\n",
    "\n",
    "            if self.modularity < self.beam[0][0]:\n",
    "                self.best_state = self.beam[0][1]  # Meilleur état trouvé\n",
    "                self.modularity = self.beam[0][0]\n",
    "        \n",
    "        return self.best_state\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
